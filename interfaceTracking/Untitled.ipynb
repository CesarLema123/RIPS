{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'log.intEnergy' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-92ca3af78d47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log.intEnergy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'log.intEnergy' does not exist"
     ]
    }
   ],
   "source": [
    "df = pd.read_table('log.intEnergy')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = \"log.intEnergy\"\n",
    "runNum = 1\n",
    "\n",
    "search = \"Step\"\n",
    "n = 1\n",
    "f = open(fileName)\n",
    "df = {}\n",
    "EOF = False\n",
    "while True:\n",
    "    try:\n",
    "        line = f.readline()\n",
    "    except:\n",
    "        break\n",
    "    if search in line:\n",
    "        if n == runNum:\n",
    "            keys = line.split()\n",
    "            for key in keys:\n",
    "                df[key] = []\n",
    "            while True:\n",
    "                try:\n",
    "                    line = f.readline()\n",
    "                except:\n",
    "                    EOF = True\n",
    "                    break\n",
    "                try:\n",
    "                    values = list(float(x) for x in line.split())\n",
    "                except:\n",
    "                    break\n",
    "                for i in range(len(keys)):\n",
    "                    df[keys[i]].append(values[i])\n",
    "        else:\n",
    "            n += 1\n",
    "    else:\n",
    "        pass\n",
    "    if len(df.keys()) > 0 or EOF:\n",
    "        break\n",
    "df = pd.DataFrame(df)\n",
    "f.close()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working Log file Reader "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test code for class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'log.interfaceTracking'   #takes in filename\n",
    "thermoLabels = 'Step Atoms Temp Press TotEng'.split()    #take in thermo output Labels/arguements\n",
    "includeLabelsForNewRun = False\n",
    "\n",
    "dataLines = []\n",
    "\n",
    "f = open(filename,'r')\n",
    "data = False\n",
    "for line in f.readlines():\n",
    "    #print(line.split())\n",
    "    \n",
    "    if data:\n",
    "        if len(line.split())!= 0 and line.split()[0].isdigit():\n",
    "            dataLines.append(line.split())\n",
    "        else:\n",
    "            data = False\n",
    "    \n",
    "    if line.split() == thermoLabels:\n",
    "        data = True\n",
    "        if includeLabelsForNewRun:\n",
    "            dataLines.append(line.split())\n",
    "    \n",
    "f.close()\n",
    "\n",
    "for i in dataLines:\n",
    "    print(i)\n",
    "\n",
    "#print(outputLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataLines,columns=thermoLabels)\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual Reader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReader:\n",
    "    def __init__(self,filename,thermoLabels):\n",
    "        self.var = \"holder\"\n",
    "        self.filename = filename\n",
    "        self.thermoLabels = thermoLabels.split()\n",
    "    \n",
    "    # get lines of thermo output data as list of lines\n",
    "    def dataExtracter(self,includeLabelsForNewRun=False):\n",
    "        self.includeLabelsForNewRun = includeLabelsForNewRun\n",
    "\n",
    "        dataLines = []\n",
    "        \n",
    "        f = open(filename,'r')\n",
    "        isDataLine = False\n",
    "        for line in f.readlines():\n",
    "            if isDataLine:\n",
    "                if len(line.split())!= 0 and line.split()[0].isdigit():\n",
    "                    dataLines.append(line.split())\n",
    "                else:\n",
    "                    isDataLine = False\n",
    "            \n",
    "            if line.split() == self.thermoLabels:\n",
    "                isDataLine = True\n",
    "                if includeLabelsForNewRun:     #used to seperate runs by thermoLabels\n",
    "                    dataLines.append(line.split())\n",
    "\n",
    "        f.close()\n",
    "        return dataLines\n",
    "\n",
    "    #User method to get dataframe from log data\n",
    "    def getDataFrame(self,seperateRunsByThermoLabels=False):\n",
    "        return pd.DataFrame(self.dataExtracter(seperateRunsByThermoLabels),columns=self.thermoLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reader = LogReader('log.interfaceTracking','Step Atoms Temp Press TotEng Enthalpy')\n",
    "df = reader.getDataFrame()\n",
    "print(reader.getDataFrame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working Grapher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#collection of methods that analyze dataframe data\n",
    "class LogAnalyzer:\n",
    "    def __init__(self,dataframe,timestep=1):\n",
    "        self.df = dataframe\n",
    "        self.timestep = timestep\n",
    "        \n",
    "    def generalPlot(self,X,Y,xlabel='',ylabel='',title=''):\n",
    "        plt.plot(X,Y)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        #plt.legend(loc='upper left')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        \n",
    "    def plotColumn(self,columnLabel):\n",
    "        Y = self.df[columnLabel].values.astype(float)\n",
    "        X = np.linspace(0,self.timestep*len(Y),len(Y))\n",
    "        self.generalPlot(X,Y,'Runtime',columnLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA = LogAnalyzer(df)\n",
    "LA.plotColumn('TotEng')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading position vectors from dump files; Working DumpReader class\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#implementation assumes that atom ids are in same order for each run, seems to be the case need to confirm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DumpReader:\n",
    "    def __init__(self,filename, outputLabels = ''):\n",
    "        self.filename = filename\n",
    "        self.outputLabels = ('ITEM: ATOMS '+ outputLabels).split()\n",
    "    \n",
    "    def dataExtracter(self):\n",
    "        dataLines = []         # format : [[rowData1], [rowData2], [rowData3], ... ]\n",
    "        self.idLabels = ['Timestep']      # format : ['Timestep', 'atomID', 'atomID', ... ]\n",
    "        rowData = []                      # format : [[timestep], [x,y,z], [x,y,z], ... ]\n",
    "        \n",
    "        f = open(self.filename,'r')\n",
    "        isFirstRun = True\n",
    "        isDataLine = False          # when initially set, line in next iteration is a data line\n",
    "        isTimestepLine = False      # when initially set, line in next iteration is a timestep line\n",
    "        timestep = 0\n",
    "        \n",
    "        for line in f.readlines():  \n",
    "            if line.strip() == 'ITEM: TIMESTEP' or isTimestepLine:\n",
    "                if isTimestepLine:\n",
    "                    isTimestepLine = False\n",
    "                    timestep = int(line.split()[0])\n",
    "                    rowData.append([timestep])\n",
    "                    if timestep > 0:                 #assumes simulation starts at 0 timestep\n",
    "                        isFirstRun = False\n",
    "                else:\n",
    "                    isTimestepLine = True\n",
    "            \n",
    "            if isDataLine:  \n",
    "                data = line.split()\n",
    "                if len(line.split())!= 0 and data[0].isdigit():   \n",
    "                    if isFirstRun: \n",
    "                        self.idLabels.append(data[0])   # append label\n",
    "                    rowData.append(line.split()[1:])   \n",
    "                else:\n",
    "                    isDataLine = False\n",
    "                    dataLines.append(rowData)\n",
    "                    rowData = []\n",
    "            \n",
    "            if line.split() == self.outputLabels:    \n",
    "                isDataLine = True                     \n",
    "                \n",
    "        f.close()\n",
    "        return dataLines\n",
    "\n",
    "    #User method to get dataframe from log data\n",
    "    def getDataframe(self):\n",
    "        return pd.DataFrame(self.dataExtracter(),columns=self.idLabels)\n",
    "    \n",
    "    def getNdArray(self):\n",
    "        data = self.dataExtracter()\n",
    "        for row in range(len(data)):\n",
    "            #data[row] = np.array(data[row])\n",
    "            for col in range(len(data[row])):\n",
    "                data[row][col] = np.array(data[row][col]).astype(float)\n",
    "        return np.array(data)\n",
    "'''\n",
    "note, tried to build dataLines as np.array but since i consistently appending new data to rowData i \n",
    "have to make a new copy and reassign (very wasteful) \n",
    "instead trying building dataLines then converting elements to np.array by looping, (is there a more efficient\n",
    "way to do this?)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for testing/proof of concept "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputLabels = 'id x y z'\n",
    "DR = DumpReader('atomParameters.data','id type c_ptm[1] c_ptm[2] c_ptm[3] c_centro')\n",
    "df = DR.getDataframe()\n",
    "data = DR.getNdArray()\n",
    "\n",
    "atomNum = 1\n",
    "atom1Data = np.array([np.array(i) for i in data[:,atomNum]])  # use this to get atom i data as shape (runs,parameters)\n",
    "\n",
    "print(atom1Data)\n",
    "#print(pd.DataFrame(data[None,:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Timestep','1r','2r','3r']\n",
    "a = [[[10],[1,2,3],[1,2,3],[1,2,3]],\n",
    "         [[20],[1,2,3],[1,2,3],[1,2,3]],\n",
    "         [[30],[1,2,3],[1,2,3],[1,2,3]],\n",
    "         [[40],[1,2,3],[1,2,3],[1,2,3]]]\n",
    "ar = np.array([[[10],[1,2,3],[1,2,3],[1,2,3]],\n",
    "         [[20],[1,2,3],[1,2,3],[1,2,3]],\n",
    "         [[30],[1,2,3],[1,2,3],[1,2,3]],\n",
    "         [[40],[1,2,3],[1,2,3],[1,2,3]]])\n",
    "pd.DataFrame(ar,columns = names)\n",
    "\n",
    "ar2 = np.array([])\n",
    "\n",
    "for row in a:\n",
    "    r = np.array([])\n",
    "    for elem in row:\n",
    "        np.append(r,np.array(elem))\n",
    "        \n",
    "    np.append(ar2,r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[1 4 7]\n"
     ]
    }
   ],
   "source": [
    "a= np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(a[:][0])\n",
    "print(a[:,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edditable DumpReader2 class to implemented data extraction using ndarrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DumpReader2:\n",
    "    def __init__(self,filename, outputLabels = ''):\n",
    "        self.filename = filename\n",
    "        self.outputLabels = ('ITEM: ATOMS '+ outputLabels).split()\n",
    "    \n",
    "    def dataExtracter(self):\n",
    "        dataLines = []         # format : [[rowData1], [rowData2], [rowData3], ... ]\n",
    "        self.idLabels = ['Timestep']      # format : ['Timestep', 'atomID', 'atomID', ... ]\n",
    "        rowData = []                      # format : [[timestep], [x,y,z], [x,y,z], ... ]\n",
    "        \n",
    "        f = open(self.filename,'r')\n",
    "        isFirstRun = True\n",
    "        isDataLine = False          # when initially set, line in next iteration is a data line\n",
    "        isTimestepLine = False      # when initially set, line in next iteration is a timestep line\n",
    "        timestep = 0\n",
    "        \n",
    "        for line in f.readlines():  \n",
    "            if line.strip() == 'ITEM: TIMESTEP' or isTimestepLine:\n",
    "                if isTimestepLine:\n",
    "                    isTimestepLine = False\n",
    "                    timestep = int(line.split()[0])\n",
    "                    rowData.append([timestep])\n",
    "                    if timestep > 0:                 #assumes simulation starts at 0 timestep\n",
    "                        isFirstRun = False\n",
    "                else:\n",
    "                    isTimestepLine = True\n",
    "            \n",
    "            if isDataLine:  \n",
    "                data = line.split()\n",
    "                if len(line.split())!= 0 and data[0].isdigit():   \n",
    "                    if isFirstRun: \n",
    "                        self.idLabels.append(data[0])   # append label\n",
    "                    rowData.append(line.split()[1:])   \n",
    "                else:\n",
    "                    isDataLine = False\n",
    "                    dataLines.append(rowData)\n",
    "                    rowData = []\n",
    "            \n",
    "            if line.split() == self.outputLabels:    \n",
    "                isDataLine = True                     \n",
    "                \n",
    "        f.close()\n",
    "        return dataLines\n",
    "\n",
    "    #User method to get dataframe from log data\n",
    "    def getDataframe(self):\n",
    "        return pd.DataFrame(self.dataExtracter(),columns=self.idLabels)\n",
    "    \n",
    "    def getNdArray(self):\n",
    "        return self.dataExtracter()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1]) array([1]) array([1])]\n"
     ]
    }
   ],
   "source": [
    "r = [[1],[1,2,3],[1,2,3]]\n",
    "a = np.empty(0)\n",
    "a = np.append(a,np.array([1,2,3]))\n",
    "b = np.asarray(r)\n",
    "for i in range(len(b)):\n",
    "    b[i] = np.array(b[0])\n",
    "    \n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to check for convergence of data to a certain value; method of DataFileAnalyzer class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import copy \n",
    "    \n",
    "    def getConstValueList(self,columnLabel):\n",
    "        yData = np.array(self.df[columnLabel].tolist())   # GET COLUMN DATA AS TARGET NDARRAY\n",
    "        yGradient = np.gradient(yData)\n",
    "        print(yGradient)\n",
    "        \n",
    "        \n",
    "        #how to decide maxError?, minRange?\n",
    "        \n",
    "    def getConstValueList2(df,columnLabel,timestepInterval=10,maxError=1,minRange=50):\n",
    "        #thermo data is outputedevrey timestepInterval\n",
    "        \n",
    "        yData = np.array(df[columnLabel].tolist()).astype(float)   # GET COLUMN DATA AS TARGET NDARRAY\n",
    "        #plt.plot(yData)\n",
    "        yGradient = np.gradient(yData)     # timestep is conserved\n",
    "        plt.plot(yGradient[20:])\n",
    "        yGGradient = np.gradient(yGradient)   # timestep is conserved\n",
    "        plt.plot(yGGradient[20:])\n",
    "        \n",
    "        #print(yData.shape,'   ',yGradient.shape,'   ',yGGradient.shape)\n",
    "        \n",
    "        constValueRanges= []\n",
    "        \n",
    "        lowRange, uppRange = -1, -1    # -1 means var is not set\n",
    "        \n",
    "\n",
    "        for ind in range(yGGradient.shape[0]):\n",
    "            #print(ind,' ',yGGradient[ind], \" low: \",lowRange,\" upp: \",uppRange,' cond: ',(uppRange == -1) and abs(yGradient[ind]) < maxError)\n",
    "            if lowRange != -1 and abs(yGGradient[ind]) < maxError:  # if lowRange is set, then can set uppRnge\n",
    "                uppRange = ind\n",
    "                if ind == (yGGradient.shape[0]-1):\n",
    "                    constValueRanges.append([lowRange,uppRange])\n",
    "            elif lowRange != -1 and uppRange != -1:\n",
    "                if abs(uppRange-lowRange) > minRange:\n",
    "                    #print(ind,' ',yGradient[ind], \" low: \",lowRange,\" upp: \",uppRange)\n",
    "                    constValueRanges.append([lowRange,uppRange])\n",
    "                lowRange = -1\n",
    "                uppRange = -1   \n",
    "                \n",
    "            \n",
    "            if (uppRange == -1):       # if uppRange is not set then can set lowRange\n",
    "                lowRange = ind\n",
    "        \n",
    "        print(constValueRanges)\n",
    "        return constValueRanges\n",
    "    \n",
    "# energy = np.mean(yData[constValueRange[0],constValueRange[1]])\n",
    "        \n",
    "    \n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-381710406f45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TotEng'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# have to find a decent way to find max Error (and alittle, but its fine rn,the min Range value)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetConstValueList3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumnLabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimestepInterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxError\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminRange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m        \u001b[0;31m#thermo data is outputedevrey timestepInterval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    " yData = np.array(df['TotEng'].tolist()).astype(float)\n",
    "\n",
    "# have to find a decent way to find max Error (and alittle, but its fine rn,the min Range value)\n",
    "def getConstValueList3(df,columnLabel,timestepInterval=10,maxError=1,minRange=10):\n",
    "        #thermo data is outputedevrey timestepInterval\n",
    "        \n",
    "        yData = np.array(df[columnLabel].tolist()).astype(float)   # GET COLUMN DATA AS TARGET NDARRAY\n",
    "        #plt.plot(yData)\n",
    "        yGradient = np.gradient(yData)     # timestep is conserved\n",
    "        #plt.plot(yGradient[20:])\n",
    "        yGGradient = np.gradient(yGradient)   # timestep is conserved\n",
    "        #plt.plot(yGGradient[20:])\n",
    "        \n",
    "        #print(yData.shape,'   ',yGradient.shape,'   ',yGGradient.shape)\n",
    "        \n",
    "        constValueRanges= []\n",
    "        \n",
    "        lowRange, uppRange = -1, -1    # -1 means var is not set\n",
    "        \n",
    "\n",
    "        for ind in range(yGGradient.shape[0]):\n",
    "            #print(ind,' ',yGGradient[ind], \" low: \",lowRange,\" upp: \",uppRange,' cond: ',(uppRange == -1) and abs(yGradient[ind]) < maxError)\n",
    "            if lowRange != -1 and abs(yGGradient[ind]) < maxError:  # if lowRange is set, then can set uppRnge\n",
    "                uppRange = ind\n",
    "                if ind == (yGGradient.shape[0]-1):\n",
    "                    constValueRanges.append([lowRange,uppRange])\n",
    "            elif lowRange != -1 and uppRange != -1:\n",
    "                if abs(uppRange-lowRange) > minRange and np.mean(yGradient[lowRange:uppRange])<maxError:\n",
    "                    #print(ind,' ',yGradient[ind], \" low: \",lowRange,\" upp: \",uppRange)\n",
    "                    constValueRanges.append([lowRange,uppRange])\n",
    "                lowRange = -1\n",
    "                uppRange = -1   \n",
    "                \n",
    "            \n",
    "            if (uppRange == -1):       # if uppRange is not set then can set lowRange\n",
    "                lowRange = ind\n",
    "                \n",
    "                \n",
    "        #STD ANALYSIS\n",
    "        yStd =[]\n",
    "        for ind in range(yData.shape[0]):\n",
    "            if ind == 0 or ind == 1:\n",
    "                yStd.append(np.std([yData[ind],yData[ind+1]]))\n",
    "            elif ind == yData.shape[0]-1 or ind == yData.shape[0]-2:\n",
    "                yStd.append(np.std([yData[ind],yData[ind-1]]))\n",
    "            else:\n",
    "                yStd.append(np.std([yData[ind-2],yData[ind-1],yData[ind],yData[ind+1],yData[ind-2]]))\n",
    "        plt.plot(yStd[10:])\n",
    "            \n",
    "            \n",
    "        \n",
    "        print(constValueRanges)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return constValueRanges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getConstValueList3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-aea215bc212e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetConstValueList3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'TotEng'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m '''\n\u001b[1;32m      4\u001b[0m \u001b[0myData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TotEng'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getConstValueList3' is not defined"
     ]
    }
   ],
   "source": [
    "lst = getConstValueList3(df,'TotEng')\n",
    "\n",
    "'''\n",
    "yData = np.array(df['TotEng'].tolist()).astype(float)[10:]\n",
    "\n",
    "subData = []\n",
    "for rang in lst:\n",
    "    subData.append(yData[rang[0]:rang[1]+1])\n",
    "    \n",
    "for subD in subData:\n",
    "    abc = getConstValueList2(pd.DataFrame(subD,columns=['ySubData']),'ySubData')\n",
    "    #dftest = pd.DataFrame(subD,columns=['ySubData'])\n",
    "    #print(dftest['ySubData'])\n",
    "    print()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f3c5d6b65551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TotEng'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# GET COLUMN DATA AS TARGET NDARRAY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#lst.append([11,146])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "yData = np.array(df['TotEng'].tolist()).astype(float)[10:]   # GET COLUMN DATA AS TARGET NDARRAY\n",
    "plt.plot(yData)\n",
    "\n",
    "#lst.append([11,146])\n",
    "\n",
    "for rang in lst:\n",
    "    y=np.ones(rang[1]-rang[0]+1)*np.mean(yData[rang[0]:rang[1]])\n",
    "    plt.plot(np.arange(rang[0],rang[1]+1),y)\n",
    "    #print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cdc6683ee888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataBin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m#ORANGE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbinDivisibleY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdataBin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbinnedY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinDivisibleY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataBin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinDivisibleY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdataBin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#binned data is along column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yData' is not defined"
     ]
    }
   ],
   "source": [
    "#Y is vector of data\n",
    "\n",
    "dataBin = 1 #ORANGE\n",
    "binDivisibleY = yData[yData.shape[0]%dataBin:]\n",
    "\n",
    "binnedY = binDivisibleY[None,:].reshape(dataBin,int(binDivisibleY.shape[0]/dataBin)) #binned data is along column\n",
    "meanBinnedY = np.mean(binnedY,axis=0)\n",
    "\n",
    "stdBin = 2 #GREENE\n",
    "binDivisibleMeanY = meanBinnedY[meanBinnedY.shape[0]%stdBin:]\n",
    "binnedMeanY = binDivisibleMeanY[None,:].reshape(stdBin,int(binDivisibleMeanY.shape[0]/stdBin)) #binned data is along column\n",
    "stdBinnedMeanY = np.std(binnedMeanY,axis=0)\n",
    "\n",
    "print(yData.shape,binDivisibleY.shape,binnedY.shape,meanBinnedY.shape, binDivisibleMeanY.shape,binnedMeanY.shape,stdBinnedMeanY.shape)\n",
    "\n",
    "#plt.plot(yData)\n",
    "plt.plot(meanBinnedY)\n",
    "plt.plot(stdBinnedMeanY)\n",
    "              \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BETTER READER CLASS FOR DUMP AND LOG OUTPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "log files output global quantities\n",
    "dump files output peratom quatities\n",
    "\n",
    "assumes run start at 0 timestep,\n",
    "assumes first line is not a dataline\n",
    "#can edit class to take in only filename and assume all log filenames begin with log.<filename>, so seperate filename by '.' and if first string is log then set output type as 'log'\n",
    "for dump:\n",
    "    assumes id is first row  # can fix this by looping through labels list and finding index and checking that index for atom ids\n",
    "    assumes ids are in same row order for in each timestep\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "class OutputReader:\n",
    "    def __init__(self,filename,outputType,dataLabels,sepUniqueRun=False):\n",
    "        self.filename = filename\n",
    "        self.outputType = outputType\n",
    "        self.datafile = None   # singe datafile for log/global qauntities or list of datafiles where each elem is a df for the ith atom\n",
    "        self.ndArray = None # singe ndarray for log/global qauntities or ndarray of ndarrays where each elem is a nda for the ith atom\n",
    "        self.dataLabels = dataLabels.split()\n",
    "        self.sepUniqueRun = sepUniqueRun\n",
    "    \n",
    "    def getDataFrame(self):\n",
    "        if self.datafile is None:\n",
    "            if self.outputType == 'log':\n",
    "                if self.sepUniqueRun == False:\n",
    "                    self.datafile = pd.DataFrame(self.getNDArray(),columns=self.dataLabels)\n",
    "                else:\n",
    "                    runKeys = []\n",
    "                    runDF = []\n",
    "                    for ind in range(self.getNDArray().shape[0]):\n",
    "                        runDF.append(pd.DataFrame(self.getNDArray()[ind],columns=self.dataLabels))\n",
    "                        runKeys.append(ind)\n",
    "                    self.datafile = pd.concat(runDF,keys=runKeys,names=['Run Number','Row Number'])\n",
    "            elif self.outputType == 'dump':\n",
    "                print('implement this code')\n",
    "                return\n",
    "            else:\n",
    "                print('Error: cannot read output type '+str(self.outputType)) # should raise an error\n",
    "                return\n",
    "        \n",
    "        return self.datafile\n",
    "    \n",
    "    def getNDArray(self):\n",
    "        if self.ndArray is None:\n",
    "            self.ndArray = np.array(self.extractData())\n",
    "        return self.ndArray\n",
    "            \n",
    "    def getDataLabels(self):\n",
    "        return self.dataLabels\n",
    "        \n",
    "    def editReader(self,newFile=None,newType=None,newDataLabels=None,sepUniqueRun=None):  # relies on reader to set correct parameters      \n",
    "        readerChanged = False          # If any reader parameter changed then have to re-ExtractData\n",
    "        \n",
    "        if newFile is not None:\n",
    "            self.filename = newFile\n",
    "            readerChanged = True\n",
    "        if newType is not None:\n",
    "            self.outputType = newType \n",
    "            readerChanged = True\n",
    "        if newDataLabels is not None:\n",
    "            self.dataLabels = newDataLabels\n",
    "            readerChanged = True\n",
    "        if sepUniqueRun is not None:\n",
    "            self.sepUniqueRun = sepUniqueRun\n",
    "            readerChanged = True\n",
    "            \n",
    "        if readerChanged:     \n",
    "            self.datafile = None \n",
    "            self.ndArray = None\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def extractData(self):\n",
    "        didNotfindDataLabels = True  # check if data labels were found atleast once\n",
    "        \n",
    "        if self.outputType == 'dump':\n",
    "            dataHeader = 'ITEM: ATOMS'.split() + self.dataLabels \n",
    "        elif self.outputType == 'log':  \n",
    "            dataHeader =  self.dataLabels\n",
    "        \n",
    "        f = open(self.filename,'r')\n",
    "        runData = []\n",
    "        if self.sepUniqueRun:            \n",
    "            dataCollection = []\n",
    "        isDataLine = False                 # identify if current line is file data line\n",
    "\n",
    "        for line in f.readlines():          # for first iteration, assumes first line will not be a data line\n",
    "            if isDataLine:                  #true when line is data line and adds it to data collection\n",
    "                if len(line.split()) != 0 and line.split()[0].isdigit():     # assumes data line starts an numeric value\n",
    "                    runData.append(line.split())\n",
    "                else:\n",
    "                    isDataLine = False\n",
    "            \n",
    "            if line.split() == dataHeader:        #find the output label line preceding the rows of data\n",
    "                didNotfindDataLabels = False \n",
    "                isDataLine = True                       # sets following line as a file dataline\n",
    "                if self.sepUniqueRun:             # make data lines array of arrays for each run\n",
    "                    dataCollection.append(np.array(runData))\n",
    "                    runData = []\n",
    "        f.close()\n",
    "        \n",
    "        if didNotfindDataLabels:\n",
    "            print('ERROR: did not find data with current datalabels')\n",
    "            return []   # should raise an error instead of returning empty list\n",
    "        else:\n",
    "            if not self.sepUniqueRun:\n",
    "                return runData\n",
    "            else:\n",
    "                dataCollection.append(np.array(runData))\n",
    "                return dataCollection[1:] # first item is always an empty list if data is found\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same files as above but version 2 trying to make reader work with dump files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "log files output global quantities\n",
    "dump files output peratom quatities\n",
    "\n",
    "assumes run start at 0 timestep,\n",
    "assumes first line is not a dataline\n",
    "#can edit class to take in only filename and assume all log filenames begin with log.<filename>, so seperate filename by '.' and if first string is log then set output type as 'log'\n",
    "\n",
    "for dump:\n",
    "    assumes id is first row  # can fix this by looping through labels list and finding index and checking that index for atom ids\n",
    "    assumes ids are in same row order for in each timestep\n",
    "    assumes no clear way in datafile to differentiate run commans, in log data is grouped by run commands\n",
    "\n",
    "'''\n",
    "\n",
    "class OutputReader:\n",
    "    def __init__(self,filename,outputType,dataLabels,sepUniqueRun=False):\n",
    "        self.filename = filename\n",
    "        self.outputType = outputType\n",
    "        self.datafile = None   # singe datafile for log/global qauntities or list of datafiles where each elem is a df for the ith atom\n",
    "        self.ndArray = None # singe ndarray for log/global qauntities or ndarray of ndarrays where each elem is a nda for the ith atom\n",
    "        self.dataLabels = dataLabels.split()\n",
    "        self.sepUniqueRun = sepUniqueRun\n",
    "    \n",
    "    def getDataFrame(self):\n",
    "        if self.datafile is None:\n",
    "            if self.outputType == 'log':\n",
    "                if self.sepUniqueRun == False:\n",
    "                    self.datafile = pd.DataFrame(self.getNDArray(),columns=self.dataLabels)\n",
    "                else:\n",
    "                    runKeys = []\n",
    "                    runDF = []\n",
    "                    for ind in range(self.getNDArray().shape[0]):\n",
    "                        runDF.append(pd.DataFrame(self.getNDArray()[ind],columns=self.dataLabels))\n",
    "                        runKeys.append(ind)\n",
    "                    self.datafile = pd.concat(runDF,keys=runKeys,names=['Run Number','Row Number'])\n",
    "            elif self.outputType == 'dump':\n",
    "                runKeys, runDF = [], []\n",
    "                for ind in range(self.getNDArray().shape[0]):\n",
    "                    runDF.append(pd.DataFrame(self.getNDArray()[ind],columns=['step']+self.dataLabels))\n",
    "                    runKeys.append(ind+1)\n",
    "                self.datafile = pd.concat(runDF,keys=runKeys,names=['Atom Number','Row Number'])\n",
    "                \n",
    "        return self.datafile\n",
    "    \n",
    "    def getNDArray(self):\n",
    "        if self.ndArray is None:\n",
    "            if self.outputType == 'log':\n",
    "                self.ndArray = np.array(self.extractLogData())\n",
    "            elif self.outputType == 'dump':\n",
    "                self.ndArray = np.array(self.extractDumpData())\n",
    "            else:\n",
    "                print('Error: cannot read output type '+str(self.outputType)) # should raise an error\n",
    "                return\n",
    "        return self.ndArray\n",
    "            \n",
    "    def getDataLabels(self):\n",
    "        return self.dataLabels\n",
    "        \n",
    "    def editReader(self,newFile=None,newType=None,newDataLabels=None,sepUniqueRun=None):  # relies on reader to set correct parameters      \n",
    "        readerChanged = False          # If any reader parameter changed then have to re-ExtractData\n",
    "        \n",
    "        if newFile is not None:\n",
    "            self.filename = newFile\n",
    "            readerChanged = True\n",
    "        if newType is not None:\n",
    "            self.outputType = newType \n",
    "            readerChanged = True\n",
    "        if newDataLabels is not None:\n",
    "            self.dataLabels = newDataLabels\n",
    "            readerChanged = True\n",
    "        if sepUniqueRun is not None:\n",
    "            self.sepUniqueRun = sepUniqueRun\n",
    "            readerChanged = True\n",
    "            \n",
    "        if readerChanged:     \n",
    "            self.datafile = None \n",
    "            self.ndArray = None\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def extractLogData(self):\n",
    "        didNotfindDataLabels = True  # check if data labels were found atleast once\n",
    "        \n",
    "        dataHeader =  self.dataLabels\n",
    "        if self.sepUniqueRun:            \n",
    "            dataCollection = []\n",
    "\n",
    "        f = open(self.filename,'r')\n",
    "        runData = []\n",
    "        isDataLine = False                 # identify if current line is file data line\n",
    "\n",
    "        for line in f.readlines():          # for first iteration, assumes first line will not be a data line\n",
    "            if isDataLine:                  #true when line is data line and adds it to data collection\n",
    "                if len(line.split()) != 0 and line.split()[0].isdigit():     # assumes data line starts an numeric value\n",
    "                    runData.append(line.split())\n",
    "                else:\n",
    "                    isDataLine = False\n",
    "            \n",
    "            if line.split() == dataHeader:        #find the output label line preceding the rows of data\n",
    "                didNotfindDataLabels = False \n",
    "                isDataLine = True                       # sets following line as a file dataline\n",
    "                if self.sepUniqueRun:             # make data lines array of arrays for each run\n",
    "                    dataCollection.append(np.array(runData))\n",
    "                    runData = []\n",
    "        f.close()\n",
    "        \n",
    "        if didNotfindDataLabels:\n",
    "            print('ERROR: did not find data with current datalabels')\n",
    "            return []   # should raise an error instead of returning empty list\n",
    "        else:\n",
    "            if not self.sepUniqueRun:\n",
    "                return runData\n",
    "            else:\n",
    "                dataCollection.append(np.array(runData))\n",
    "                return dataCollection[1:] # first item is always an empty list if data is found\n",
    "\n",
    "    def extractDumpData(self):\n",
    "        dataHeader = 'ITEM: ATOMS'.split() + self.dataLabels \n",
    "\n",
    "        f = open(self.filename,'r')\n",
    "        datalines = [line.strip().split() for line in f.readlines()]\n",
    "        numAtoms = int(datalines[datalines.index('ITEM: NUMBER OF ATOMS'.split())+1][0])\n",
    "        widthOfHeader = datalines.index('ITEM: ATOMS'.split()+self.dataLabels)+1 \n",
    "        totData = []\n",
    "        numRows = int(len(datalines)/(numAtoms+widthOfHeader))\n",
    "        linesBeforeAtomRepeat = numAtoms+widthOfHeader\n",
    "        \n",
    "        for i in range(numAtoms):\n",
    "            atomDataLineInd = widthOfHeader+i\n",
    "            timestepArray = [datalines[datalines.index('ITEM: TIMESTEP'.split())+1+(ind*linesBeforeAtomRepeat)] for ind in range(numRows)]\n",
    "            totData.append(np.array([timestepArray[ind]+datalines[atomDataLineInd+(ind*linesBeforeAtomRepeat)] for ind in range(numRows)]))\n",
    " \n",
    "        f.close()\n",
    "       \n",
    "        return totData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = OutputReader('log.interfaceTracking','log','Step Atoms Temp Press TotEng Enthalpy')\n",
    "\n",
    "#print(a.getNDArray())\n",
    "#print(a.getDataFrame())\n",
    "#print(a.getDataLabels())\n",
    "a.editReader(sepUniqueRun=True)\n",
    "#print(a.filename,' ',a.outputType,' ',a.dataLabels,' ',a.sepUniqueRun,' ',a.datafile,' ',a.ndArray)\n",
    "#print(a.getDataFrame())\n",
    "#print(a.getNDArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['type', 'id', 'x', 'y', 'z', 'c_ptm[1]', 'c_centro', 'c_cna'] \n",
      "\n",
      "            step type   id        x        y        z c_ptm[1]     c_centro  \\\n",
      "Row Number                                                                    \n",
      "0              0    1  100     7.26    9.075    1.815        1  5.04871e-29   \n",
      "1             10    1  100     7.26    9.075    1.815        1  5.04871e-29   \n",
      "2             20    1  100  7.26048  9.07628  1.81562        1    0.0107859   \n",
      "3             30    1  100  7.26076  9.08028  1.81758        1    0.0563253   \n",
      "4             40    1  100  7.25965   9.0881  1.82121        1     0.116235   \n",
      "5             50    1  100   7.2564  9.09992  1.82636        1     0.142991   \n",
      "6             60    1  100  7.25187  9.11468  1.83255        1     0.155105   \n",
      "7             70    1  100  7.24786   9.1306  1.83914        1     0.238659   \n",
      "8             80    1  100  7.24451  9.14553  1.84558        1     0.342857   \n",
      "9             90    1  100   7.2408  9.15639  1.85113        1     0.421059   \n",
      "10           100    1  100  7.23654  9.16088   1.8564        1     0.492042   \n",
      "11           110    1  100  7.23178  9.15815  1.86097        1     0.503419   \n",
      "12           120    1  100  7.22665  9.14928  1.86479        1      0.50861   \n",
      "13           130    1  100  7.22138  9.13609  1.86809        1     0.572057   \n",
      "14           140    1  100  7.21534   9.1203  1.87017        1     0.509752   \n",
      "15           150    1  100  7.20742  9.10377  1.87055        1     0.425634   \n",
      "16           160    1  100  7.19868  9.08854   1.8687        1      0.39192   \n",
      "17           170    1  100  7.19138    9.077  1.86372        1     0.313185   \n",
      "18           180    1  100  7.18594  9.07027  1.85618        1     0.253398   \n",
      "19           190    1  100  7.18104  9.06937  1.84794        1     0.227545   \n",
      "20           200    1  100   7.1765   9.0748  1.84107        1     0.266521   \n",
      "21           210    1  100  7.17272  9.08647  1.83738        1     0.345999   \n",
      "22           220    1  100  7.16981  9.10361  1.83781        1     0.404374   \n",
      "23           230    1  100  7.17082  9.12686  1.84294        1     0.438359   \n",
      "24           240    1  100  7.17805  9.15413  1.85315        1     0.496217   \n",
      "25           250    1  100  7.19165  9.18037  1.86853        1     0.677878   \n",
      "26           260    1  100  7.21237  9.19953  1.88812        1     0.879308   \n",
      "27           270    1  100  7.24048  9.20671    1.909        1     0.962523   \n",
      "28           280    1  100  7.27111  9.20149  1.92769        1     0.849916   \n",
      "29           290    1  100   7.2979  9.18597  1.94246        1     0.769838   \n",
      "...          ...  ...  ...      ...      ...      ...      ...          ...   \n",
      "72           720    1  100  6.51165  9.04706  2.09138        0      4.61645   \n",
      "73           730    1  100  6.51006  8.97088   2.0358        0      3.84804   \n",
      "74           740    1  100  6.51807  8.92338  1.98663        0      1.69165   \n",
      "75           750    1  100  6.54237  8.91715  1.96906        0      3.52955   \n",
      "76           760    1  100  6.57111  8.95255  1.99543        0      3.48586   \n",
      "77           770    1  100  6.59489  9.02631  2.04782        0      3.50227   \n",
      "78           780    1  100  6.60034  9.12203  2.07513        0      3.75483   \n",
      "79           790    1  100  6.57838  9.21965  2.03379        0      3.51789   \n",
      "80           800    1  100  6.53906   9.3086    1.926        0      4.51678   \n",
      "81           810    1  100  6.50488  9.38161  1.79026        0      4.96974   \n",
      "82           820    1  100  6.48817  9.41331  1.68248        0      5.40168   \n",
      "83           830    1  100  6.48349  9.37087  1.65334        0      2.89962   \n",
      "84           840    1  100  6.48341  9.27045  1.69456        0      1.51207   \n",
      "85           850    1  100  6.48042  9.16975  1.75782        0      1.12869   \n",
      "86           860    1  100   6.4654  9.10268  1.81524        0      4.71713   \n",
      "87           870    1  100  6.44166  9.07807  1.86171        0      5.25562   \n",
      "88           880    1  100  6.42366   9.0906  1.89633        0       5.7859   \n",
      "89           890    1  100  6.42278  9.12246  1.91713        0      6.03535   \n",
      "90           900    1  100  6.44506    9.159  1.92174        0      5.86192   \n",
      "91           910    1  100  6.49044  9.18299  1.90783        0      3.00499   \n",
      "92           920    1  100  6.55272  9.18398  1.86848        0      2.06715   \n",
      "93           930    1  100  6.61985  9.17047  1.80472        0      1.44193   \n",
      "94           940    1  100  6.67703  9.15681  1.73281        0      1.25516   \n",
      "95           950    1  100  6.71036  9.15606  1.68014        0      1.39308   \n",
      "96           960    1  100   6.7134  9.17694   1.6672        1      1.31386   \n",
      "97           970    1  100  6.69705   9.2176   1.6929        1      1.29135   \n",
      "98           980    1  100  6.68233  9.26497   1.7417        1      1.39858   \n",
      "99           990    1  100  6.68489  9.30406  1.79725        1      1.62831   \n",
      "100         1000    1  100   6.7076  9.32468  1.84738        1      1.82748   \n",
      "101         1010    1  100  6.74517  9.31985  1.88049        1      2.03847   \n",
      "\n",
      "           c_cna  \n",
      "Row Number        \n",
      "0              5  \n",
      "1              5  \n",
      "2              5  \n",
      "3              5  \n",
      "4              5  \n",
      "5              5  \n",
      "6              5  \n",
      "7              5  \n",
      "8              5  \n",
      "9              5  \n",
      "10             5  \n",
      "11             5  \n",
      "12             5  \n",
      "13             5  \n",
      "14             5  \n",
      "15             5  \n",
      "16             5  \n",
      "17             5  \n",
      "18             5  \n",
      "19             5  \n",
      "20             5  \n",
      "21             5  \n",
      "22             5  \n",
      "23             5  \n",
      "24             5  \n",
      "25             5  \n",
      "26             5  \n",
      "27             5  \n",
      "28             5  \n",
      "29             5  \n",
      "...          ...  \n",
      "72             5  \n",
      "73             5  \n",
      "74             5  \n",
      "75             5  \n",
      "76             5  \n",
      "77             5  \n",
      "78             5  \n",
      "79             5  \n",
      "80             5  \n",
      "81             5  \n",
      "82             5  \n",
      "83             5  \n",
      "84             5  \n",
      "85             5  \n",
      "86             5  \n",
      "87             5  \n",
      "88             5  \n",
      "89             5  \n",
      "90             5  \n",
      "91             5  \n",
      "92             5  \n",
      "93             5  \n",
      "94             5  \n",
      "95             5  \n",
      "96             5  \n",
      "97             5  \n",
      "98             5  \n",
      "99             5  \n",
      "100            5  \n",
      "101            5  \n",
      "\n",
      "[102 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "nd array looks like:\n",
    "[id_1_data,id_2,data,...]\n",
    "[[step,param1,param2,...],[step,param1,param2,...],[step,param1,param2,...],[step,param1,param2,...]]\n",
    "\n",
    "if\n",
    "\n",
    "'''\n",
    "\n",
    "a = OutputReader('pos.XYZ','dump','type id x y z c_ptm[1] c_centro c_cna')\n",
    "\n",
    "print(a.dataLabels,'\\n')\n",
    "print(a.getDataFrame().xs(100))\n",
    "#print(a.getNDArray()[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = pd.DataFrame(np.array([['a','a','a'],['b','b','b'],['c','c','c']]),columns=['let1','let2','let3'])\n",
    "two = pd.DataFrame(np.array([['d','d','d'],['f','f','f'],['g','g','g']]),columns=['let1','let2','let3'])\n",
    "\n",
    "df = pd.concat([one,two],keys=['1','2'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['1x1' '1y1' '1z1' '1w1']\n",
      "  ['1x2' '1y2' '1z2' '1w2']]\n",
      "\n",
      " [['2x1' '2y1' '1z1' '1w1']\n",
      "  ['2x2' '2y2' '2z2' '2w2']]\n",
      "\n",
      " [['3x1' '3y1' '3z1' '3w1']\n",
      "  ['3x2' '3y2' '3z2' '3w2']]]\n"
     ]
    }
   ],
   "source": [
    "ar1 = np.array(['1x1','1y1','1z1','1w1'])\n",
    "ar2 = np.array(['2x1','2y1','1z1','1w1'])\n",
    "ar3 = np.array(['3x1','3y1','3z1','3w1'])\n",
    "\n",
    "\n",
    "ar11 = np.array(['1x2','1y2','1z2','1w2'])\n",
    "ar22 = np.array(['2x2','2y2','2z2','2w2'])\n",
    "ar33 = np.array(['3x2','3y2','3z2','3w2'])\n",
    "\n",
    "timesteps = 2\n",
    "numAtoms = 3\n",
    "fin1 = np.array([ar1,ar2,ar3])[:,None,:]\n",
    "\n",
    "fin2 = np.array([ar11,ar22,ar33])[:,None,:]\n",
    "\n",
    "print(np.append(fin1,fin2,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "['1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 13.1769'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 13.1769' '1 2 0 inf 0 13.1769'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 13.1769' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 13.1769'\n",
      " '1 2 0 inf 0 13.1769' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 13.1769'\n",
      " '1 2 0 inf 0 13.1769' '1 2 0 inf 0 13.1769' '1 2 0 inf 0 13.1769'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 13.1769' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 13.1769'\n",
      " '1 2 0 inf 0 13.1769' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 13.1769'\n",
      " '1 2 0 inf 0 13.1769' '1 2 0 inf 0 13.1769' '1 2 0 inf 0 13.1769'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 13.1769' '1 2 0 inf 0 13.1769'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653'\n",
      " '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653' '1 2 0 inf 0 19.7653']\n"
     ]
    }
   ],
   "source": [
    "# New Method\n",
    "\n",
    "f = open('atomParameters.data','r')\n",
    "datalines = [line.strip() for line in f.readlines()]\n",
    "\n",
    "numAtoms = 648\n",
    "widthOfHeader = 9\n",
    "totData = []\n",
    "numRows = int(len(datalines)/(numAtoms+widthOfHeader))\n",
    "print(numRows)\n",
    "lineBeforeAtomRepeat = numAtoms+widthOfHeader\n",
    "for i in range(numAtoms):\n",
    "    atomDataLineInd = widthOfHeader+i\n",
    "    totData.append(np.array([datalines[atomDataLineInd+(ind*lineBeforeAtomRepeat)] for ind in range(numRows)]))\n",
    "    \n",
    "print(np.array(totData)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['1x1' '1y1' '1z1']\n",
      "  ['1x2' '1y2' '1z2']]\n",
      "\n",
      " [['2x1' '2y1' '2z1']\n",
      "  ['2x2' '2y2' '2z2']]\n",
      "\n",
      " [['3x1' '3y1' '3z1']\n",
      "  ['3x2' '3y2' '3z2']]]\n"
     ]
    }
   ],
   "source": [
    "myArr = np.array([np.array([np.array(['1x1','1y1','1z1']),np.array(['1x2','1y2','1z2'])]),[['2x1','2y1','2z1'],['2x2','2y2','2z2']],[['3x1','3y1','3z1'],['3x2','3y2','3z2']]])\n",
    "print(myArr)\n",
    "\n",
    "#(numAtoms,numTimesteps,numParam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 666 is out of bounds for axis 0 with size 101",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-a72a1b8ed1b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlineBeforeAtomRepeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 666 is out of bounds for axis 0 with size 101"
     ]
    }
   ],
   "source": [
    "print([data[9],data[9+1*lineBeforeAtomRepeat]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "print(np.array([2])+np.array([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
